{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Branch import Branch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ConjunctionSet import ConjunctionSet\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "from DataPreperation import *\n",
    "from ReadDatasetFunctions import *\n",
    "from NewModelBuilder import *\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data,x_columns,y_column = read_tic_tac_toe_dataset()\n",
    "train_x,train_y,test_x,test_y=divide_to_train_test(data,x_columns,y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=3, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=3,max_depth=3)\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of branches before filterring: 32\n",
      "number of branches after filterring: 32\n",
      "i=0\n",
      "number of branches before filterring: 176\n",
      "number of branches after filterring: 176\n",
      "i=1\n"
     ]
    }
   ],
   "source": [
    "cs=ConjunctionSet(x_columns, data, model, amount_of_branches_threshold=1000, filter_approach='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=cs.get_conjunction_set_df().round(decimals=5)\n",
    "for i in range(2):\n",
    "    df[model.classes_[i]]=[probas[i] for probas in df['probas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dict={}\n",
    "for col in df.columns:\n",
    "    df_dict[col]=df[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "node=Node([True]*len(df))\n",
    "node.split(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9e0a662043c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#print(model.predict_proba(inst)[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_probas_and_depth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print(prediction)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mrf_prediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sagio\\Google Drive\\phd\\phd_code\\Node.py\u001b[0m in \u001b[0;36mpredict_probas_and_depth\u001b[1;34m(self, inst, training_df)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_feature\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Node' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for indx,inst in enumerate(test_x):\n",
    "    #print('branch:')\n",
    "    for i,b in enumerate(cs.conjunctionSet):\n",
    "        if b.containsInstance(inst):\n",
    "            probas_sum=np.sum(b.label_probas)\n",
    "            break\n",
    "    #print(model.predict_proba(inst)[0])\n",
    "    prediction,depth=node.predict_probas_and_depth(inst,df_dict)\n",
    "    #print(prediction)\n",
    "    rf_prediction=model.predict_proba(inst)[0]\n",
    "    #print(rf_prediction)\n",
    "    \n",
    "    if np.argmax(prediction) != np.argmax(rf_prediction):\n",
    "        print(prediction)\n",
    "        #print(b.label_probas/probas_sum)\n",
    "        print(rf_prediction)\n",
    "        print(test_y[indx])\n",
    "        print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_depth(t,indx):\n",
    "    if t.feature[indx] == -2:\n",
    "        return 1\n",
    "    return 1 + max(get_depth(t,t.children_left[indx]),get_depth(t,t.children_right[indx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_depth(t,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est=model.estimators_[0]\n",
    "t = est.tree_\n",
    "t.children_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for indx,inst in enumerate(test_x):\n",
    "    #print('branch:')\n",
    "    for i,b in enumerate(cs.conjunctionSet):\n",
    "        if b.containsInstance(inst):\n",
    "            probas_sum=np.sum(b.label_probas)\n",
    "            #print(b.label_probas/probas_sum)\n",
    "    #print(model.predict_proba(inst)[0])\n",
    "    prediction,depth=node.predict_probas_and_depth(inst,df_dict)\n",
    "    #print(prediction)\n",
    "    rf_prediction=model.predict_proba(inst)[0]\n",
    "    #print(rf_prediction)\n",
    "    \n",
    "    if np.argmax(prediction) != np.argmax(rf_prediction):\n",
    "        print(prediction)\n",
    "        print(rf_prediction)\n",
    "        print(test_y[indx])\n",
    "        print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=node.right.right.right.right.right.right.right.right\n",
    "n.get_node_prediction(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[node.right.right.right.right.left.right.right.get_node_prediction(df_dict)]\n",
    "v=df_dict['probas'][node.right.right.right.right.left.right.right.mask][0]\n",
    "v=[i/np.sum(v) for i in v]\n",
    "np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node.left.right.left.left.check_feature_split_value(df,'1_lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=node.left.right.left.left\n",
    "feature_columns=[col for col in df.columns if 'lower' in col or 'upper' in col]\n",
    "relevant_cols=[col for col in feature_columns if len(set(df[n.mask][col])) > 1]\n",
    "relevant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=node.left.right.left.left\n",
    "col='1_lower'\n",
    "threshold_to_devision_value={}\n",
    "if 'upper' in col:\n",
    "    for threshold in set(df[n.mask][col]):\n",
    "        right_size = len([i for i in df[n.mask][col.replace('upper','lower')] if i > threshold])\n",
    "        left_size = len(df[n.mask]) - right_size\n",
    "        threshold_to_devision_value[threshold]=np.abs(left_size-right_size)\n",
    "else:\n",
    "    for threshold in set(df[n.mask][col]):\n",
    "        right_size = len([i for i in df[n.mask][col.replace('lower','upper')] if i <= threshold])\n",
    "        left_size = len(df[n.mask]) - right_size\n",
    "        threshold_to_devision_value[threshold] = np.abs(left_size - right_size)\n",
    "threshold = min(threshold_to_devision_value, key=threshold_to_devision_value.get)\n",
    "val= threshold_to_devision_value[threshold]\n",
    "print(threshold,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for inst in test_x:\n",
    "    for i,b in enumerate(cs.conjunctionSet):\n",
    "        if b.containsInstance(inst):\n",
    "            probas_sum=np.sum(b.label_probas)\n",
    "            print(b.label_probas/probas_sum)\n",
    "            print(i)\n",
    "    #print(model.predict_proba(inst)[0])\n",
    "    print(node.predict(inst,df))\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node.predict(test_x[11],df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_proba(test_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array([0,1,2])\n",
    "x+0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_proba(test_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node.predict(test_x[1],df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('branch_probability',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v=np.array([np.array(l) for l in df['probas']])\n",
    "branches_probas=np.array(df['branch_probability'].values).reshape(len(df),1)\n",
    "v=v*branches_probas\n",
    "v=v.mean(axis=0)\n",
    "v=[i/sum(v) for i in v]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[node.left.left.left.left.left.left.left.mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[node.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.left.mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=node.left.left.left.left.left.left.select_random_split_feature(df,[col for col in df.columns if '_' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=node.left.left.left.left.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if 'lower' not in col:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(node.left.split_feature)\n",
    "print(node.left.split_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[node.left.left.mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(node.left.left.split_feature)\n",
    "print(node.left.left.split_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[node.left.left.left.mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(node.left.left.left.split_feature)\n",
    "print(node.left.left.left.split_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_mask=node.left.left.left.mask\n",
    "left_mask=node.left.left.left.left_mask\n",
    "for i,j,k,h in zip(original_mask,left_mask,list(np.logical_and(original_mask,left_mask)),original_mask and left_mask):\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print(k)\n",
    "    print(h)\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node.left.left.left.left_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in t.value:\n",
    "    print(np.argmax(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=new_model_builder.model\n",
    "t=model.tree_\n",
    "new_tree_features=new_model_builder.feature_names\n",
    "new_features=[]\n",
    "new_thresholds=[]\n",
    "original_features=[(int(i.split('<')[0]),float(i.split('<')[1])) for i in new_tree_features]\n",
    "for feature,threshold in zip(t.feature,t.threshold):\n",
    "    if feature<0:\n",
    "        new_features.append(feature)\n",
    "        new_thresholds.append(threshold)\n",
    "        continue\n",
    "    new_features.append(original_features[feature][0])\n",
    "    new_thresholds.append(original_features[feature][1])\n",
    "new_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records=[]\n",
    "for b in mg.conjunctionSet:\n",
    "    records.extend(b.get_branch_records())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(records).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est=rf.estimators_[0]\n",
    "t=est.tree_\n",
    "export_graphviz(t,out_file='tree.dot',feature_names=iris.feature_names,class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
