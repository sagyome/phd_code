{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Branch import Branch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ConjunctionSet import ConjunctionSet\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "from DataPreperation import *\n",
    "from ReadDatasetFunctions import *\n",
    "from NewModelBuilder import *\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data,x_columns,y_column = read_iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_prediction(X,rf):\n",
    "    predictions=[]\n",
    "    depths=[]\n",
    "    for inst in X:\n",
    "        pred=[]\n",
    "        depth=0\n",
    "        for base_model in rf.estimators_:\n",
    "            res=tree_depth_and_prediction(inst,base_model.tree_)\n",
    "            pred.append(res[0])\n",
    "            depth+=res[1]\n",
    "        predictions.append(np.array(pred).mean(axis=0))\n",
    "        depths.append(depth)\n",
    "    return predictions,depths\n",
    "def tree_depth_and_prediction(inst,t):\n",
    "    indx=0\n",
    "    depth=0\n",
    "    while t.feature[indx]>=0:\n",
    "        if inst[t.feature[indx]]<=t.threshold[indx]:\n",
    "            indx=t.children_left[indx]\n",
    "        else:\n",
    "            indx = t.children_right[indx]\n",
    "        depth+=1\n",
    "    return np.array([float(i)/np.sum(t.value[indx][0]) for i in t.value[indx][0]]) ,depth\n",
    "    #return np.array(t.value[indx][0]) ,depth\n",
    "preds=ensemble_prediction(test_x,rf)[0]\n",
    "rf_preds=rf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5,  2.5,  5. ,  6. ])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1=np.array([1,2,3,4])\n",
    "arr2=np.array([2,3,7,8])\n",
    "np.array([arr1,arr2]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 0.   0.3  0.7]\n",
      "[ 0.   0.3  0.7]\n",
      "-----------\n",
      "[ 0.   0.3  0.7]\n",
      "[ 0.   0.4  0.6]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.   0.1  0.9]\n",
      "[ 0.   0.1  0.9]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 0.   0.9  0.1]\n",
      "[ 0.   0.9  0.1]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.   0.1  0.9]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.   0.1  0.9]\n",
      "[ 0.   0.1  0.9]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 0.  1.  0.]\n",
      "[ 0.  1.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 0.   0.8  0.2]\n",
      "[ 0.   0.8  0.2]\n",
      "-----------\n",
      "[ 1.  0.  0.]\n",
      "[ 1.  0.  0.]\n",
      "-----------\n",
      "[ 0.   0.3  0.7]\n",
      "[ 0.   0.3  0.7]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n",
      "[ 0.  0.  1.]\n",
      "[ 0.  0.  1.]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for i1,i2 in zip(rf_preds,preds):\n",
    "    print(i1)\n",
    "    print(i2)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-10 16:01:43.774609\t Start creating branches\n",
      "Iteration 1: 8 conjunctions\n",
      "number of branches before filterring: 28\n",
      "number of branches after filterring: 24\n",
      "Iteration 2: 24 conjunctions\n",
      "number of branches before filterring: 28\n",
      "number of branches after filterring: 28\n",
      "Iteration 3: 28 conjunctions\n",
      "number of branches before filterring: 54\n",
      "number of branches after filterring: 50\n",
      "Iteration 4: 50 conjunctions\n",
      "number of branches before filterring: 68\n",
      "number of branches after filterring: 60\n",
      "Iteration 5: 60 conjunctions\n",
      "number of branches before filterring: 88\n",
      "number of branches after filterring: 84\n",
      "Iteration 6: 84 conjunctions\n",
      "number of branches before filterring: 87\n",
      "number of branches after filterring: 85\n",
      "Iteration 7: 85 conjunctions\n",
      "number of branches before filterring: 102\n",
      "number of branches after filterring: 91\n",
      "Iteration 8: 91 conjunctions\n",
      "number of branches before filterring: 207\n",
      "number of branches after filterring: 167\n",
      "Iteration 9: 167 conjunctions\n",
      "number of branches before filterring: 334\n",
      "number of branches after filterring: 273\n",
      "2018-04-10 16:01:44.163889\t created branches\n",
      "2018-04-10 16:01:44.215926\t draw predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagio\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for i in range(1):\n",
    "    train_x,train_y,test_x,test_y=divide_to_train_test(data,x_columns,y_column )\n",
    "    rf=RandomForestClassifier(n_estimators=10)\n",
    "    rf.fit(train_x,train_y)\n",
    "    print(str(datetime.datetime.now())+'\\t Start creating branches')\n",
    "    cs=ConjunctionSet(x_columns,data,rf)\n",
    "    print(str(datetime.datetime.now())+'\\t created branches')\n",
    "    rf_predicions=rf.predict(test_x)\n",
    "    conjunctionPredictions=cs.predict(test_x)\n",
    "    print(str(datetime.datetime.now())+'\\t draw predictions')\n",
    "    new_model_builder=NewModelBuilder(cs.get_conjunction_set_df())\n",
    "    new_model_builder.train_new_model()\n",
    "    new_model_builder.new_model_processing()\n",
    "    disagreements=np.sum(conjunctionPredictions!=rf_predicions)\n",
    "    d={}\n",
    "    preds=[]\n",
    "    for i in test_x:\n",
    "        preds.append(rf.classes_[np.argmax(new_model_builder.predict_instance_probas(i)[0])])\n",
    "    d['number_of_disagreements_with_branches']=disagreements\n",
    "    d['new_model_accuracy']=np.sum(preds==test_y)/len(test_y)\n",
    "    d['new_model_disagreement']=np.sum(preds!=rf_predicions)/len(test_y)\n",
    "    d['rf_accuracy']=np.sum(rf_predicions==test_y)/len(test_y)\n",
    "    results.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'new_model_accuracy': 0.9555555555555556,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 1,\n",
       "  'rf_accuracy': 0.9555555555555556},\n",
       " {'new_model_accuracy': 0.97777777777777775,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 0,\n",
       "  'rf_accuracy': 0.97777777777777775},\n",
       " {'new_model_accuracy': 0.8666666666666667,\n",
       "  'new_model_disagreement': 0.022222222222222223,\n",
       "  'number_of_disagreements_with_branches': 0,\n",
       "  'rf_accuracy': 0.88888888888888884},\n",
       " {'new_model_accuracy': 0.93333333333333335,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 0,\n",
       "  'rf_accuracy': 0.93333333333333335},\n",
       " {'new_model_accuracy': 1.0,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 1,\n",
       "  'rf_accuracy': 1.0},\n",
       " {'new_model_accuracy': 0.9555555555555556,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 1,\n",
       "  'rf_accuracy': 0.9555555555555556},\n",
       " {'new_model_accuracy': 0.9555555555555556,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 1,\n",
       "  'rf_accuracy': 0.9555555555555556},\n",
       " {'new_model_accuracy': 0.97777777777777775,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 0,\n",
       "  'rf_accuracy': 0.97777777777777775},\n",
       " {'new_model_accuracy': 0.9555555555555556,\n",
       "  'new_model_disagreement': 0.0,\n",
       "  'number_of_disagreements_with_branches': 0,\n",
       "  'rf_accuracy': 0.9555555555555556},\n",
       " {'new_model_accuracy': 0.97777777777777775,\n",
       "  'new_model_disagreement': 0.044444444444444446,\n",
       "  'number_of_disagreements_with_branches': 0,\n",
       "  'rf_accuracy': 0.97777777777777775}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model_builder=NewModelBuilder(cs.get_conjunction_set_df())\n",
    "new_model_builder.train_new_model()\n",
    "new_model_builder.new_model_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {        'oob_score': True,\n",
    "                  'criterion': 'entropy',\n",
    "                  'max_depth': 10,\n",
    "                  'class_weight': 'balanced',\n",
    "                  'min_samples_leaf': 10,\n",
    "                  'max_features': 'auto',\n",
    "                  'n_jobs': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='entropy', max_depth=10, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=100,**params)\n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in test_x:\n",
    "    preds.append(rf.classes_[np.argmax(new_model_builder.predict_instance_probas(i)[0])])\n",
    "np.sum(preds!=rf_predicions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.feature=np.array(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in t.value:\n",
    "    print(np.argmax(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=new_model_builder.model\n",
    "t=model.tree_\n",
    "new_tree_features=new_model_builder.feature_names\n",
    "new_features=[]\n",
    "new_thresholds=[]\n",
    "original_features=[(int(i.split('<')[0]),float(i.split('<')[1])) for i in new_tree_features]\n",
    "for feature,threshold in zip(t.feature,t.threshold):\n",
    "    if feature<0:\n",
    "        new_features.append(feature)\n",
    "        new_thresholds.append(threshold)\n",
    "        continue\n",
    "    new_features.append(original_features[feature][0])\n",
    "    new_thresholds.append(original_features[feature][1])\n",
    "new_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records=[]\n",
    "for b in mg.conjunctionSet:\n",
    "    records.extend(b.get_branch_records())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(records).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est=rf.estimators_[0]\n",
    "t=est.tree_\n",
    "export_graphviz(t,out_file='tree.dot',feature_names=iris.feature_names,class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
